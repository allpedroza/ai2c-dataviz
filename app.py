import os, re, csv, glob, argparse, warnings
from typing import List, Optional, Dict, Tuple
from datetime import datetime
import traceback

warnings.filterwarnings("ignore")

import pandas as pd
import numpy as np
import dash
from dash import dcc, html, Input, Output, State, MATCH, ALL
import dash_bootstrap_components as dbc
import plotly.express as px
import plotly.graph_objs as go
import plotly.io as pio
import io, base64
import boto3
import json

# ==============================
# 0) Helper para exibir erros na UI
# ==============================
# PATCH: m√°scara sem reindex
def _non_empty_mask(s: pd.Series) -> pd.Series:
    s2 = s.astype(str)
    return s2.str.strip().ne("") & ~s2.str.strip().str.lower().isin({"nan","none","null"})

# PATCH: pega o primeiro campo n√£o-vazio para usar no gr√°fico
def _first_nonempty_series(sub: pd.DataFrame, candidates: list[str]) -> tuple[pd.Series, str|None]:
    for c in candidates:
        if c in sub.columns:
            s = sub[c].dropna().astype(str)
            m = _non_empty_mask(s)
            s = s[m]
            if not s.empty:
                return s, c
    return pd.Series(dtype=str), None


def _error_box(title: str, exc: Exception) -> html.Div:
    """Retorna um componente Dash exibindo o stack trace completo."""
    return html.Div(
        [
            html.H4(title, className="mb-2 text-danger"),
            html.Pre(
                traceback.format_exc(),
                style={
                    "whiteSpace": "pre-wrap",
                    "backgroundColor": "#f8f9fa",
                    "padding": "1rem",
                    "borderRadius": "8px",
                    "fontSize": "0.85rem",
                    "border": "1px solid #dee2e6"
                }
            )
        ],
        className="muted-box",
    )

# ==============================
# 1) Inicializa√ß√£o de Vari√°veis Globais
# ==============================
KEY = os.getenv("KEY", "")
EXPORT_HTML = False
PORT = int(os.getenv("PORT", "8080"))
LIKERT_1_5_IDS = set()
QDESC_MAP = {}
df_main = pd.DataFrame()

# ==============================
# 2) Setup e Constantes
# ==============================
try:
    from wordcloud import WordCloud, STOPWORDS
    HAS_WORDCLOUD = True
except ImportError:
    HAS_WORDCLOUD = False
    STOPWORDS = set()

# Cache para DataFrames carregados, chaveado por (ambiente, key)
DF_CACHE: Dict[Tuple[str, str], pd.DataFrame] = {}

# Configura√ß√µes de S3 a partir de vari√°veis de ambiente
S3_BUCKET_BASE = os.getenv("S3_BUCKET_BASE", "ai2c-genai").strip()
S3_REPORTS_PREFIX = os.getenv("S3_REPORTS_PREFIX", "ai2c-reports/reports").strip().strip("/")
S3_INPUTS_PREFIX = os.getenv("S3_INPUTS_PREFIX", "integrador-inputs").strip().strip("/")
AWS_REGION = os.getenv("AWS_REGION", "sa-east-1")

# Modo local: se definido, carrega arquivos do diret√≥rio local sem usar S3
LOCAL_MODE = os.getenv("LOCAL_MODE", "").lower() in ("true", "1", "yes", "sim")
LOCAL_DATA_DIR = os.getenv("LOCAL_DATA_DIR", "local_data")

#. s3://ai2c-genai/integrador-inputs/6864dcc63d7d7502472acc62-questionnaires.csv


# Colunas obrigat√≥rias no CUBE
REQUIRED_COLS = [
    "questionnaire_id","survey_id","respondent_id","date_of_response",
    "question_id","orig_answer","category","topic","sentiment","intention",
    "question_description"
]

# Colunas opcionais + valores padr√£o
OPTIONAL_COL_DEFAULTS = {
    "confidence_level": None,
}

NON_SEGMENTABLE = set(REQUIRED_COLS + list(OPTIONAL_COL_DEFAULTS.keys()) + ["answer", "orig_answer", "respondent_id"])

RAW_FILTER_COLS = ["category","topic","sentiment","intention","question_description","canal adesao","cluster"]

def raw_controls(df: pd.DataFrame):
    ops = {}
    for c in RAW_FILTER_COLS:
        if c in df.columns:
            vals = (df[c].dropna().astype(str).str.strip()
                    .loc[lambda s: s.ne("") & ~s.str.lower().isin({"nan","none","null"})]
                    .unique().tolist())
            vals.sort()
            ops[c] = [{"label": v, "value": v} for v in vals]
        else:
            ops[c] = []
    grid = []
    for c in RAW_FILTER_COLS:
        grid.append(
            html.Div([
                html.Label(c, className="fw-bold"),
                dcc.Dropdown(id={"type":"raw-filter","col":c},
                             options=ops[c], multi=True, placeholder=f"Filtrar {c}...")
            ])
        )
    return html.Div(className="ctrl-grid", children=grid)

# Mapeamento e estilo para Sentimento
SENTIMENT_ORDER = ["negativo", "neutro", "positivo"]
SENTIMENT_COLORS = {"positivo": "#10B981", "negativo": "#EF4444", "neutro": "#9CA3AF"}

SENTIMENT_MAP = {
    "pos": "positivo", "positivo": "positivo", "positive": "positivo",
    "neg": "negativo", "negativo": "negativo", "negative": "negativo",
    "neu": "neutro",   "neutro":   "neutro",   "neutral":  "neutro",
}

def normalize_sentiment(val) -> Optional[str]:
    if val is None or (isinstance(val, float) and pd.isna(val)):
        return None
    v = str(val).strip().lower()
    return SENTIMENT_MAP.get(v, v)

# ===== Helpers de normaliza√ß√£o do question√°rio (PATCH NOVO) =====
def _norm_txt(x: str) -> str:
    if x is None:
        return ""
    x = str(x)
    x = x.strip().strip('"').strip("'")
    x = re.sub(r"\s+", " ", x)
    return x

def apply_bar_labels(fig: go.Figure) -> go.Figure:
    fig.update_traces(texttemplate="%{y}", textposition="outside", cliponaxis=False)
    fig.update_layout(uniformtext_minsize=8, uniformtext_mode="hide")
    return fig
 

def _norm_qtype(qt: str) -> str:
    qt = _norm_txt(qt).lower().replace("_", "-")
    # sinon√≠mias comuns (pt/en)
    if qt in {"open-ended","open ended","texto","texto livre","campo aberto","aberta","comment","text"}:
        return "open-ended"
    if qt in {"multiple-choice","multiple choice","m√∫ltipla escolha","multipla escolha","checkbox","multi"}:
        return "multiple-choice"
    if qt in {"single-choice","single choice","categorica","categ√≥rica","categoria","radiogroup","dropdown"}:
        return "single-choice"
    if qt in {"number","numeric","rating","nps","escala"}:
        return "numeric"
    return qt


# Filtros da aba "Dados Brutos"
RAW_FILTER_SPECS = [
    ("category",              "Categoria",              "raw-dd-category"),
    ("topic",                 "T√≥pico",                 "raw-dd-topic"),
    ("sentiment",             "Sentimento",             "raw-dd-sentiment"),
    ("intention",             "Inten√ß√£o",               "raw-dd-intention"),
    ("question_description",  "Pergunta",               "raw-dd-qdesc"),
    ("canal adesao",          "Canal ades√£o",           "raw-dd-canal"),
    ("cluster",               "Cluster",                "raw-dd-cluster"),
]

def _dropdown_options(df: pd.DataFrame, col: str, shorten: bool = False):
    if col not in df.columns:
        return []
    s = (df[col]
         .dropna()
         .astype(str)
         .map(lambda x: x.strip())
         .loc[lambda s: s.ne("") & ~s.str.lower().isin({"nan", "none", "null"})]
         .unique()
    )
    vals = sorted(s.tolist())
    if shorten:
        return [{"label": (v[:120] + "‚Ä¶" if len(v) > 120 else v), "value": v} for v in vals]
    return [{"label": v, "value": v} for v in vals]

def raw_filters_view(df: pd.DataFrame) -> dbc.Card:
    """Card de filtros do Raw."""
    rows = []
    for col, label, cid in RAW_FILTER_SPECS:
        opts = _dropdown_options(df, col, shorten=(col == "question_description"))
        ctrl = dbc.Col([
            html.Label(label, className="fw-bold"),
            dcc.Dropdown(
                id=cid, multi=True, options=opts, placeholder=f"Todos(as) {label.lower()}",
                clearable=True, maxHeight=320, optionHeight=32, disabled=(len(opts) == 0)
            )
        ], md=4)
        rows.append(ctrl)

    return dbc.Card([
        dbc.CardHeader(html.H5("Filtros", className="mb-0")),
        dbc.CardBody([
            html.Div(dbc.Row(rows, className="g-3")),
            html.Div(id="raw-filter-summary", className="text-muted mt-2", style={"fontSize": ".9rem"})
        ])
    ], className="mb-3 dash-card")

# ==============================
# 3) Estilo Plotly (AI2C style)
# ==============================
pio.templates["modern"] = go.layout.Template(
    layout=go.Layout(
        paper_bgcolor="white", plot_bgcolor="white",
        font=dict(family="Poppins, system-ui, -apple-system, Segoe UI, Roboto, Helvetica Neue, Arial, sans-serif", size=13, color="#111111"),
        title=dict(x=0, xanchor="left", font=dict(size=18, color="#111111")),
        margin=dict(l=40, r=20, t=60, b=40),
        colorway=["#FF9800", "#FFB74D", "#FFA726", "#FB8C00", "#EF6C00", "#6C757D", "#111111"],
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0, bgcolor="rgba(255,255,255,0)"),
        xaxis=dict(showgrid=False, zeroline=False, showline=True, linecolor="#ECECEC", linewidth=1, ticks="outside", tickcolor="#ECECEC"),
        yaxis=dict(showgrid=True, gridcolor="#F3F4F6", gridwidth=1, zeroline=False, showline=False),
        hoverlabel=dict(bgcolor="white", font=dict(color="#111111"), bordercolor="#ECECEC"),
    )
)
pio.templates.default = "modern"

# ==============================
# 4) Fun√ß√µes de Carregamento e Prepara√ß√£o de Dados
# ==============================
def normalize_env(env_in: str) -> str:
    e = (env_in or "").strip().lower()
    return "prod" if e in {"prd", "prod"} else "dev"

def resolve_bucket(env_resolved: str) -> str:
    return S3_BUCKET_BASE if env_resolved == "prod" else f"{S3_BUCKET_BASE}-{env_resolved}"

def s3_path_for_key(env_resolved: str, key: str) -> str:
    bucket = resolve_bucket(env_resolved)
    return f"s3://{bucket}/{S3_REPORTS_PREFIX}/{key}/{key}_analytics_cube.csv"

def _s3_download_to_tmp(env_resolved: str, key: str) -> Optional[str]:
    """Baixa s3://.../{key}_analytics_cube.csv p/ /tmp e retorna caminho local, ou None se falhar."""
    # MODO LOCAL: Tenta carregar do diret√≥rio local primeiro
    if LOCAL_MODE:
        local_candidates = [
            os.path.join(LOCAL_DATA_DIR, f"{key}_analytics_cube.csv"),
            f"{key}_analytics_cube.csv",  # raiz do projeto
        ]
        for local_path in local_candidates:
            if os.path.exists(local_path):
                print(f"[LOCAL] Carregando cube de {local_path}")
                return local_path
        print(f"[LOCAL] Nenhum arquivo local encontrado para key={key}")
        return None

    # MODO S3: Download do S3
    s3_uri = s3_path_for_key(env_resolved, key)
    _, _, rest = s3_uri.partition("s3://")
    bucket, _, keypath = rest.partition("/")
    local_dir = os.getenv("DATA_DIR", "/tmp")
    os.makedirs(local_dir, exist_ok=True)
    local_path = os.path.join(local_dir, f"{key}_analytics_cube.csv")
    s3 = boto3.client("s3", region_name=AWS_REGION)
    try:
        print(f"[S3] Baixando {s3_uri} para {local_path}")
        s3.download_file(bucket, keypath, local_path)
        print(f"[S3] Download de {s3_uri} conclu√≠do.")
        return local_path
    except Exception as e:
        print(f"[S3] Falha ao baixar {s3_uri}: {e}")
        return None

def read_csv_robust(path: str) -> pd.DataFrame:
    for enc in ["utf-8", "utf-8-sig", "latin1", "iso-8859-1"]:
        try:
            with open(path, "r", encoding=enc, errors="ignore") as f:
                sample = f.read(4096)
                delim = csv.Sniffer().sniff(sample, delimiters=",;\t|").delimiter
            df = pd.read_csv(path, sep=delim, encoding=enc, dtype=str, na_values=["", "NA", "N/A", "null", "NULL", "None"])
            df.columns = df.columns.str.strip()
            print(f"‚úì CSV lido: {os.path.basename(path)} | enc={enc} sep='{delim}'")
            return df
        except Exception:
            continue
    return pd.read_csv(path, sep=None, engine="python", encoding="utf-8", on_bad_lines="skip", dtype=str)



def _s3_read_text(bucket: str, key: str) -> Optional[str]:
    # MODO LOCAL: Tenta ler do diret√≥rio local primeiro
    if LOCAL_MODE:
        # key geralmente √© algo como "integrador-inputs/employee-survey-demo-questionnaires.csv"
        # vamos tentar tanto o caminho completo quanto apenas o nome do arquivo
        filename = key.split("/")[-1]  # pega s√≥ o nome do arquivo
        local_candidates = [
            os.path.join(LOCAL_DATA_DIR, filename),
            filename,  # raiz do projeto
        ]
        for local_path in local_candidates:
            if os.path.exists(local_path):
                try:
                    with open(local_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    print(f"[LOCAL] Lido {local_path}. Tamanho: {len(content)} bytes.")
                    return content
                except Exception as e:
                    print(f"[LOCAL] Erro ao ler {local_path}: {e}")
        print(f"[LOCAL] Arquivo n√£o encontrado localmente: {key}")
        return None

    # MODO S3: L√™ do S3
    try:
        s3 = boto3.client("s3", region_name=AWS_REGION)
        obj = s3.get_object(Bucket=bucket, Key=key)
        content = obj["Body"].read().decode("utf-8", errors="ignore")
        print(f"[DEBUG] SUCESSO ao ler s3://{bucket}/{key}. Tamanho: {len(content)} bytes.")
        return content
    except Exception as e:
        print(f"[S3] not found: s3://{bucket}/{key} ({e})")
        return None

# ==============================
# SE√á√ÉO: Metadados de Question√°rios (REFATORADO)
# ==============================


# Cache unificado para metadados de question√°rios
QUESTION_META_CACHE = {}

def load_questionnaire_meta(env_resolved: str, key: str) -> dict:
    """Carrega tipos/op√ß√µes/t√≠tulos do question√°rio.
       Prioridade: JSON > CSV. Busca no bucket do ambiente e, se faltar, no bucket base (ai2c-genai)."""
    cache_key = (env_resolved, key)
    if cache_key in QUESTION_META_CACHE:
        return QUESTION_META_CACHE[cache_key]

    env_bucket  = resolve_bucket(env_resolved)        # ex.: ai2c-genai-dev
    base_bucket = S3_BUCKET_BASE                      # ex.: ai2c-genai
    paths = [
        f"{S3_INPUTS_PREFIX}/{key}-questionnaires.json",
        f"{S3_INPUTS_PREFIX}/{key}-questionnaires.csv",
    ]

    def _from_parsed_dict(parsed: dict) -> dict:
        raw_qtypes  = parsed.get("qtypes", {}) or {}
        qtypes_norm = {}
        for qid, qt in raw_qtypes.items():
            qt_n = _norm_qtype(qt)
            if qt_n == "text":        qt_n = "open-ended"
            if qt_n == "categorical": qt_n = "single-choice"
            if qt_n == "multiple":    qt_n = "multiple-choice"
            qtypes_norm[str(qid)] = qt_n

        qopts   = parsed.get("qopts", {}) or {}
        qtitles = parsed.get("qtitles", {}) or {}
        return {
            "qtype_map":    qtypes_norm,
            "options_map":  {str(k): list(v) for k, v in qopts.items()},
            "title_map":    {str(k): str(v) for k, v in qtitles.items()},
            "open_questions": {str(k) for k, v in qtypes_norm.items() if v == "open-ended"},
        }

    # 1) TENTA JSON nos dois buckets (env depois base). Se achar, retorna imediatamente.
    for bucket in (env_bucket, base_bucket):
        skey = paths[0]  # JSON
        txt = _s3_read_text(bucket, skey)
        if txt:
            try:
                parsed = _parse_questionnaires_json(txt)
                meta = _from_parsed_dict(parsed)
                QUESTION_META_CACHE[cache_key] = meta
                print(f"[META] OK JSON em s3://{bucket}/{skey} ‚áí tipos: {meta.get('qtype_map')}")
                return meta
            except Exception as e:
                print("[questionnaire meta] parse JSON error:", skey, e)

    # 2) Se JSON n√£o existir, TENTA CSV nos dois buckets.
    for bucket in (env_bucket, base_bucket):
        skey = paths[1]  # CSV
        txt = _s3_read_text(bucket, skey)
        if txt:
            try:
                parsed = _parse_questionnaires_csv(txt)
                meta = _from_parsed_dict(parsed)
                QUESTION_META_CACHE[cache_key] = meta
                print(f"[META] OK CSV em s3://{bucket}/{skey} ‚áí tipos: {meta.get('qtype_map')}")
                return meta
            except Exception as e:
                print("[questionnaire meta] parse CSV error:", skey, e)

    # 3) Fallback vazio (vai cair na heur√≠stica s√≥ se for necess√°rio)
    empty = {"qtype_map": {}, "options_map": {}, "title_map": {}, "open_questions": set()}
    QUESTION_META_CACHE[cache_key] = empty
    print("[META] N√£o encontrado JSON/CSV de question√°rio; usando heur√≠stica como fallback.")
    return empty



def _csv_options_looks_broken(parsed: dict) -> bool:
    """Detecta CSV exportado com answer_options='[object Object]'."""
    qopts = (parsed or {}).get("qopts", {}) or {}
    for opts in qopts.values():
        for o in opts:
            if str(o).strip() == "[object Object]":
                return True
    return False

def _parse_questionnaires_json(text: str) -> dict:
    import json as _json
    data = _json.loads(text)

    def _normtype(t: str, max_sel, choices) -> str:
        t = (t or "").strip().lower()
        # regras alinhadas com o jq:
        if t in {"text", "comment", "open-ended"}:
            return "open-ended"
        if t in {"radiogroup", "dropdown"}:
            return "single-choice"
        if t in {"checkbox"}:
            try:
                m = int(max_sel) if max_sel is not None else 99
            except Exception:
                m = 99
            return "single-choice" if m == 1 else "multiple-choice"
        if t in {"rating", "number", "numeric"}:
            return "numeric"
        # fallback: se tem choices, assume single-choice; sen√£o open-ended
        if (choices or []):
            return "single-choice"
        return "open-ended"

    qtypes, qopts, qtitles = {}, {}, {}
    try:
        pages = (data.get("content") or {}).get("pages") or []
        for p in pages:
            for el in p.get("elements", []) or []:
                qid = str(el.get("name", "")).strip()
                if not qid:
                    continue
                raw_type = el.get("type")
                max_sel  = el.get("maxSelectedChoices")
                choices  = el.get("choices") or []
                # mapeia t√≠tulos/op√ß√µes
                qtitles[qid] = (el.get("title") or qid)
                labels = []
                for ch in choices:
                    if isinstance(ch, dict):
                        labels.append(str(ch.get("text") or ch.get("value") or "").strip())
                    else:
                        labels.append(str(ch).strip())
                labels = [x for x in labels if x]
                if labels:
                    qopts[qid] = labels
                # tipo normalizado
                qtypes[qid] = _normtype(raw_type, max_sel, choices)
    except Exception as e:
        print("[parse questionnaires json] error:", e)

    return {"qtypes": qtypes, "qopts": qopts, "qtitles": qtitles}


def _parse_questionnaires_csv(text: str) -> dict:
    """
    Parser para formato CSV do question√°rio.
    Fallback quando JSON n√£o est√° dispon√≠vel.
    """
    from io import StringIO
    
    qtype_map = {}
    options_map = {}
    title_map = {}
    open_questions = set()
    scale_questions = set()
    
    try:
        # CSV com ; e SEM converter "" em NaN
        dfq = pd.read_csv(StringIO(text), sep=";", dtype=str, keep_default_na=False, encoding="utf-8")
        
        # Normaliza colunas b√°sicas
        for col in ["topic", "questionnaire_id", "survey_id", "question_id",
                    "question_description", "question_type", "answer_options", "marked"]:
            if col not in dfq.columns:
                dfq[col] = ""
            dfq[col] = dfq[col].map(_norm_txt)

        for _, r in dfq.iterrows():
            qid = _norm_txt(r.get("question_id", ""))
            if not qid:
                continue
            
            qdesc = _norm_txt(r.get("question_description", ""))
            qtype_raw = _norm_qtype(r.get("question_type", ""))
            opts_raw = _norm_txt(r.get("answer_options", ""))

            # Fallback: se n√£o veio tipo, infere por presen√ßa de op√ß√µes
            if not qtype_raw:
                qtype_raw = "multiple-choice" if bool(opts_raw) else "open-ended"

            # Mapeia para tipos de visualiza√ß√£o padronizados
            if qtype_raw in {"open-ended", "comment", "text"}:
                viz_type = "open-ended"
                open_questions.add(qid)
            elif qtype_raw in {"multiple-choice", "checkbox", "multi"}:
                viz_type = "multiple-choice"
            elif qtype_raw in {"single-choice", "radiogroup", "dropdown", "categorical"}:
                viz_type = "single-choice"
            elif qtype_raw in {"rating", "numeric", "number"}:
                viz_type = "rating-scale"
                scale_questions.add(qid)
            else:
                viz_type = qtype_raw  # mant√©m o original se n√£o reconhecido

            # Detecta escalas de satisfa√ß√£o pelo t√≠tulo
            title_lower = qdesc.lower()
            if any(word in title_lower for word in ["satisfeito", "satisfa√ß√£o", "avalia", "escala"]):
                viz_type = "rating-scale"
                scale_questions.add(qid)
            
            qtype_map[qid] = viz_type
            title_map[qid] = qdesc

            # Parse das op√ß√µes (se existirem)
            if opts_raw:
                opts_list = [o.strip() for o in re.split(r"[|;,/]", opts_raw) if o.strip()]
                # Remove "[object Object]" inv√°lidos
                opts_list = [o for o in opts_list if "object" not in o.lower()]
                if opts_list:
                    options_map[qid] = opts_list

    except Exception as e:
        print(f"[_parse_questionnaires_csv] Erro: {e}")
        import traceback
        traceback.print_exc()
    
    return {
        "qtype_map": qtype_map,
        "options_map": options_map,
        "title_map": title_map,
        "open_questions": open_questions,
        "scale_questions": scale_questions
    }


# Fun√ß√£o auxiliar para obter tipo de visualiza√ß√£o
def get_visualization_type(question_id: str, meta: dict) -> str:
    """
    Retorna o tipo de visualiza√ß√£o apropriado para uma pergunta.
    
    Tipos poss√≠veis:
    - "open-ended": wordcloud, an√°lise de sentimentos
    - "rating-scale": gr√°fico de barras horizontal (escala de satisfa√ß√£o)
    - "single-choice": gr√°fico de pizza ou barras
    - "multiple-choice": gr√°fico de barras (m√∫ltiplas sele√ß√µes)
    - "yes-no": gr√°fico de pizza simples
    - "numeric": histograma
    """
    return meta.get("qtype_map", {}).get(question_id, "open-ended")


def qtype_for(env_resolved: str, key: str, qid: str, df: Optional[pd.DataFrame] = None) -> str:
    """
    Prioriza metadado do question√°rio; cai para analyze_qtype(df) se necess√°rio.
    
    COMPATIBILIDADE: Mant√©m a interface original mas usa o novo load_questionnaire_meta.
    """
    meta = load_questionnaire_meta(env_resolved, key)
    qt = (meta.get("qtype_map") or {}).get(str(qid), "").lower()
    
    if qt:
        # J√° vem normalizado
        return qt
    
    if df is None or df.empty:
        return "unknown"
    
    # Fallback: analisa heuristicamente
    guessed = analyze_qtype(df["answer"]) if "answer" in df.columns else "unknown"
    
    # Converte heur√≠stica para os nomes usados na UI
    mapper = {
        "numeric": "numeric",
        "categorical": "single-choice",
        "multiple": "multiple-choice",
        "text": "open-ended",
        "open-ended": "open-ended"
    }
    return mapper.get(guessed, guessed)

def get_qtype_for_question_with_meta(env_resolved: str, qid: str, series: pd.Series, key: str) -> str:
    meta = load_questionnaire_meta(env_resolved, key)
    qt = (meta.get("qtype_map", {}) or {}).get(str(qid))
    if qt:
        return qt
    # fallback s√≥ se n√£o houver meta
    guessed = analyze_qtype(series)
    mapper = {"numeric":"numeric","categorical":"single-choice","multiple":"multiple-choice","text":"open-ended","open-ended":"open-ended"}
    return mapper.get(guessed, "open-ended")



def build_state(df: pd.DataFrame, env_resolved: Optional[str] = None, key: Optional[str] = None) -> Dict:
    """Cria um dicion√°rio de estado a partir de um DataFrame + metadados do question√°rio."""
    if df.empty:
        return {
            "stats": {},
            "questions_df": pd.DataFrame(),
            "QDESC_MAP": {},
            "ALLOWED_SEGMENT_COLS": [],
            "QTYPE_MAP": {},
            "QOPTIONS_MAP": {}
        }

    def _allowed_segment_cols(d: pd.DataFrame) -> list[str]:
        cols = []
        for c in d.columns:
            if c in NON_SEGMENTABLE or is_pii(c) or high_cardinality(d, c):
                continue
            cols.append(c)
        return sorted(cols)

    stats = {
        "total_responses": len(df),
        "unique_respondents": df["respondent_id"].nunique() if "respondent_id" in df.columns else 0,
        "unique_questions": df["question_id"].nunique() if "question_id" in df.columns else 0,
        "start": df["date_of_response"].min() if "date_of_response" in df.columns else None,
        "end": df["date_of_response"].max() if "date_of_response" in df.columns else None,
    }

    qdf = df[["question_id", "question_description"]].drop_duplicates()
    qdf["__ord"] = qdf["question_id"].apply(numeric_suffix)
    qdf = qdf.sort_values(["__ord", "question_id"]).drop(columns="__ord")

    qdesc_map = {
        str(r["question_id"]): (r["question_description"] or str(r["question_id"]))
        for _, r in qdf.iterrows()
    }

    qtype_map, qopts_map = {}, {}
    
    if env_resolved and key:
        meta = load_questionnaire_meta(env_resolved, key)
        qtype_map = (meta.get("qtype_map") or {}).copy()
        qopts_map = (meta.get("options_map") or {}).copy()
        
        # Enriquece qdesc_map com t√≠tulos do question√°rio
        for qid, title in (meta.get("title_map") or {}).items():
            if title and qid in qdesc_map:
                # Usa t√≠tulo do question√°rio se a descri√ß√£o estiver vazia
                if not qdesc_map[qid].strip():
                    qdesc_map[qid] = title

    return {
        "stats": stats,
        "questions_df": qdf,
        "QDESC_MAP": qdesc_map,
        "ALLOWED_SEGMENT_COLS": _allowed_segment_cols(df),
        "QTYPE_MAP": qtype_map,
        "QOPTIONS_MAP": qopts_map,
    }


def fix_mojibake(s: str) -> str:
    if not isinstance(s, str): return s
    rep = {"‚àö¬£":"√£","‚àö‚â•":"√≥","‚àö¬∞":"√°","‚àö¬©":"√©","‚àö‚Ñ¢":"√™","‚àö‚à´":"√∫","‚àö¬∫":"√∫","‚àö√ü":"√ß",
           "∆í√Ç¬£":"√£","∆í√Ç¬°":"√°","∆í√Ç¬©":"√©","∆í√Ç¬™":"√™","∆í√Ç¬∫":"√∫","∆í√Ç¬≥":"√≥","∆í√Ç¬ß":"√ß","∆í√É¬±":"√±",
           "N‚àö¬£o":"N√£o","n‚àö¬£o":"n√£o"}
    for k,v in rep.items(): s = s.replace(k,v)
    return s

def coerce_sentiment_series(s: pd.Series) -> pd.Series:
    if s is None or s.empty:
        return pd.Series(dtype=str)
    s_base = s.astype(str).str.strip().str.lower()
    return s_base.map(SENTIMENT_MAP).fillna(s_base)

def intention_bar_fig(sub_df: pd.DataFrame, top_n: int = 20) -> Optional[go.Figure]:
    if sub_df.empty:
        return None
    intent_col = None
    for name in ["intention","intent","intencao"]:
        if name in sub_df.columns:
            intent_col = name
            break
    if not intent_col:
        return None

    s = _clean_series_for_counts(sub_df[intent_col])
    if s.empty:
        return None

    vc = s.value_counts().head(top_n)
    df_bar = pd.DataFrame({"Inten√ß√£o": vc.index, "Qtde": vc.values})
    fig = px.bar(df_bar, x="Inten√ß√£o", y="Qtde", title="Inten√ß√µes ‚Äì Top respostas")
    fig.update_traces(text=df_bar["Qtde"], textposition="outside", cliponaxis=False)
    fig = create_fig_style(fig, x="Inten√ß√£o", y="Qtde")
    fig.update_xaxes(showgrid=False, showticklabels=True)
    fig.update_yaxes(showgrid=False, showticklabels=True)
    return responsive_axis(fig, labels=df_bar["Inten√ß√£o"].tolist())


def load_df_for_key(env_resolved: str, key: str) -> pd.DataFrame:
    """Carrega DF do CUBE para (env, key) com cache em mem√≥ria e download do S3 se necess√°rio."""
    k = (env_resolved, key)
    if k in DF_CACHE:
        return DF_CACHE[k]

    local_path = _s3_download_to_tmp(env_resolved, key)
    if not local_path or not os.path.exists(local_path):
        fallback_path = f"{key}_analytics_cube.csv"
        print(f"Download do S3 falhou. Tentando fallback local: {fallback_path}")
        if os.path.exists(fallback_path):
            local_path = fallback_path
        else:
            raise FileNotFoundError(f"Cubo de dados n√£o encontrado para key='{key}' no ambiente='{env_resolved}'")

    df = read_csv_robust(local_path)
    
    missing = [c for c in REQUIRED_COLS if c not in df.columns]
    if missing:
        raise ValueError(f"Colunas obrigat√≥rias ausentes no CUBE: {missing}")

    for col, default in OPTIONAL_COL_DEFAULTS.items():
        if col not in df.columns:
            df[col] = default

    for c in REQUIRED_COLS:
        df[c] = df[c].astype(str).map(lambda x: x.strip() if isinstance(x, str) else x).replace({"nan": None, "None": None})

    for c in ["question_description","category","topic","sentiment","intention"]:
        if c in df.columns:
            df[c] = df[c].astype(str).map(fix_mojibake)

    if "sentiment" in df.columns:
        df["sentiment"] = df["sentiment"].map(normalize_sentiment)

    if "date_of_response" in df.columns:
        df["date_of_response"] = pd.to_datetime(df["date_of_response"], errors="coerce")

    if "confidence_level" in df.columns:
        df["confidence_level"] = pd.to_numeric(df["confidence_level"], errors="coerce")

    df["answer"] = df["orig_answer"].astype(str).map(fix_mojibake)

    DF_CACHE[k] = df
    return df

# ==============================
# 5) Fun√ß√µes de An√°lise e Helpers
# ==============================
def is_pii(col: str) -> bool:
    c = (col or "").lower()
    if c == "respondent_id": return False
    patterns = [
        r"\bcpf\b", r"\bcnpj\b", r"\brg\b", r"\bdoc", r"document", r"\bpassport\b", r"e[-_ ]?mail",
        r"\bemail\b", r"\btelefone\b", r"\bphone\b", r"\bcelular\b", r"\bwhatsapp\b", r"\bendere",
        r"\baddress\b", r"\bcep\b", r"\bzipcode\b", r"\bnome\b", r"\bname\b", r"\bid\b", r"\bip\b",
        r"lat", r"lon", r"longitude", r"latitude", r"device", r"imei"
    ]
    return any(re.search(p, c) for p in patterns)

def intents_by_question(df_cube, qid: str):
    sub = df_cube[df_cube['question_id'] == qid]
    if 'intent' not in sub.columns:
        for alt in ('intencao', 'topic', 'classe_intencao'):
            if alt in sub.columns:
                sub = sub.rename(columns={alt: 'intent'})
                break
    if 'intent' not in sub.columns:
        return pd.DataFrame(columns=['intent','count','pct'])

    ct = (sub.assign(intent=sub['intent'].fillna('Sem classifica√ß√£o'))
             .groupby('intent', dropna=False)
             .size()
             .reset_index(name='count')
             .sort_values('count', ascending=False))
    total = ct['count'].sum() or 1
    ct['pct'] = (ct['count'] / total * 100).round(1)
    return ct

def make_minimal(fig: go.Figure) -> go.Figure:
    fig.update_xaxes(showgrid=False, zeroline=False, showline=False, showticklabels=False)
    fig.update_yaxes(showgrid=False, zeroline=False, showline=False, showticklabels=False)
    fig.update_layout(margin=dict(l=10, r=10, t=50, b=10))
    return fig

def high_cardinality(df: pd.DataFrame, col: str, max_ratio: float = 0.2, min_unique: int = 50) -> bool:
    try:
        n = len(df)
        u = df[col].astype(str).nunique(dropna=True)
        return (u >= min_unique) and (u / max(1, n) > max_ratio)
    except Exception:
        return True

def numeric_suffix(s: str):
    m = re.search(r"(\d+)$", str(s))
    return int(m.group(1)) if m else float("inf")


def analyze_qtype(series: pd.Series) -> str:
    """Vers√£o aprimorada que considera a cardinalidade para evitar falsos positivos de 'multiple'."""
    s = series.dropna().astype(str)
    if s.empty:
        return "empty"

    num_unique = s.nunique()
    total_count = len(s)

    # Heur√≠stica 1: Se for num√©rico, √© num√©rico.
    if pd.to_numeric(s, errors="coerce").notna().mean() > 0.8:
        return "numeric"

    # Heur√≠stica 2: Se tiver alta cardinalidade, √© texto livre.
    # (Ex: mais de 60% das respostas s√£o √∫nicas)
    if total_count > 10 and (num_unique / total_count > 0.6):
        return "text"

    # Heur√≠stica 3: Verifica separadores, mas apenas se a cardinalidade n√£o for muito alta.
    has_sep = s.str.contains(r"[;,/|]").mean() > 0.02
    if has_sep and num_unique < (total_count * 0.5): # S√≥ considera 'multiple' se n√£o for quase tudo √∫nico
        return "multiple"

    # Heur√≠stica 4: Baixa cardinalidade sugere categ√≥rico.
    if num_unique <= 25:
        return "categorical"

    # Fallback final: √© texto livre.
    return "text"


def parse_multi(ans: str) -> List[str]:
    if not isinstance(ans, str) or not ans.strip():
        return []
    cleaned = re.sub(r"[,/|]", ";", ans)
    return [t.strip() for t in cleaned.split(";") if t.strip()]

def explode_multiple(sub: pd.DataFrame) -> pd.DataFrame:
    rows = []
    for _, row in sub.iterrows():
        items = parse_multi(row.get("answer", ""))
        for it in items:
            r = row.copy()
            r["answer_item"] = it
            rows.append(r)
    return pd.DataFrame(rows).reset_index(drop=True) if rows else pd.DataFrame(columns=list(sub.columns) + ["answer_item"])

def _clean_series_for_counts(s: pd.Series) -> pd.Series:
    # mant√©m o comprimento; apenas normaliza e marca inv√°lidos como NaN
    s = s.astype(str)
    s = s.str.strip()
    s = s.mask(s.eq(""), np.nan)
    s = s.mask(s.str.lower().isin({"nan","none","null"}), np.nan)
    return s


def make_pv_answer(df_q: pd.DataFrame, bins: int = 10) -> pd.DataFrame:
    out = df_q.copy()
    if out.empty or "answer" not in out.columns:
        out["__pv_answer__"] = pd.Series(dtype=str)
        return out
    qtype = analyze_qtype(out["answer"])
    if qtype == "multiple":
        out["__pv_answer__"] = out["answer"].astype(str).str.split(r"[,;/|]")
        out = out.explode("__pv_answer__")
        out["__pv_answer__"] = _clean_series_for_counts(out["__pv_answer__"])
        out = out.dropna(subset=["__pv_answer__"])
    elif qtype == "numeric":
        vals = pd.to_numeric(out["answer"], errors="coerce")
        out["__pv_answer__"] = pd.cut(vals, bins=bins, labels=[f"Faixa {i+1}" for i in range(bins)])
        out = out.dropna(subset=["__pv_answer__"])
    else:
        out["__pv_answer__"] = _clean_series_for_counts(out["answer"])
        out = out.dropna(subset=["__pv_answer__"])
    return out

def build_topics_wordcloud_component(d: pd.DataFrame, width: int = 900, height: int = 520):
    if not HAS_WORDCLOUD: return html.Div("Para a nuvem, instale: pip install wordcloud pillow")
    if d.empty or "topic" not in d.columns: return html.Div("Sem t√≥picos na sele√ß√£o atual.")
    s = d["topic"].dropna().astype(str).str.strip()
    s = s[s.ne("") & ~s.str.lower().isin({"nan","none","null"})]
    if s.empty: return html.Div("Sem t√≥picos v√°lidos para gerar a nuvem.")
    freq = s.value_counts()
    if freq.empty: return html.Div("Sem t√≥picos v√°lidos para gerar a nuvem.")
    wc = WordCloud(width=width, height=height, background_color="white", colormap="tab20c", prefer_horizontal=0.95, random_state=42, collocations=False, normalize_plurals=True, max_words=200, min_font_size=10, stopwords=STOPWORDS).generate_from_frequencies(freq.to_dict())
    buf = io.BytesIO(); wc.to_image().save(buf, format="PNG", optimize=True)
    b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
    return html.Img(src=f"data:image/png;base64,{b64}", style={"width":"100%","height":"auto"})

def responsive_axis(fig: go.Figure, labels=None, axis: str = "x"):
    n = len(labels) if labels is not None else 0
    maxlen = max((len(str(s)) for s in labels), default=0) if n > 0 else 0
    if n >= 12 or maxlen > 16: angle, size = -45, 10
    elif n >= 7 or maxlen > 12: angle, size = -25, 11
    else: angle, size = 0, 12
    if axis == "x": fig.update_xaxes(tickangle=angle, automargin=True, tickfont=dict(size=size))
    else: fig.update_yaxes(automargin=True, tickfont=dict(size=size))
    return fig

def create_fig_style(fig, title="", x="", y="", tickangle=None, showlegend=True):
    fig.update_layout(title=title, xaxis_title=x, yaxis_title=y, showlegend=showlegend, hovermode="x unified")
    if tickangle is not None: fig.update_xaxes(tickangle=tickangle)
    fig.update_xaxes(automargin=True); fig.update_yaxes(automargin=True)
    return fig

def empty_state(msg: str):
    return html.Div([html.Div("‚ìò", style={"fontSize":"18px"}), html.Span(msg)], className="muted-box")

def _extract_click_label(clickData):
    if not clickData or not clickData.get("points"): return None
    p = clickData["points"][0]
    return p.get("label", p.get("x"))

def _apply_qfilter(sub: pd.DataFrame, qfilter: Dict[str, Optional[str]]) -> pd.DataFrame:
    qfilter = qfilter or {}
    if qfilter.get("category"): sub = sub[sub["category"].astype(str) == str(qfilter["category"])]
    if qfilter.get("topic"): sub = sub[sub["topic"].astype(str) == str(qfilter["topic"])]
    return sub

def sentiment_timeline(df: pd.DataFrame, granularity: str) -> Optional[go.Figure]:
    if df.empty or "sentiment" not in df.columns or "date_of_response" not in df.columns:
        return None
    d = df.dropna(subset=["date_of_response", "sentiment"]).copy()
    if d.empty: return None
    gran = (granularity or "W")
    d["period"] = pd.to_datetime(d["date_of_response"]).dt.to_period(gran)
    trend = d.groupby(["period","sentiment"]).size().reset_index(name="count")
    if trend.empty: return None
    trend = trend.sort_values(["period","sentiment"])
    trend["period_str"] = trend["period"].astype(str)
    period_order = trend["period_str"].drop_duplicates().tolist()
    fig = px.bar(
        trend, x="period_str", y="count", color="sentiment",
        barmode="group",
        category_orders={"period_str": period_order, "sentiment": SENTIMENT_ORDER},
        color_discrete_map=SENTIMENT_COLORS,
        title=f"Tend√™ncia de Sentimento ({ {'D':'Di√°rio','W':'Semanal','M':'Mensal'}.get(gran, gran) })"
    )
    return create_fig_style(fig, x="Per√≠odo", y="Qtde", tickangle=-30, showlegend=True)

def sentiment_percentages(df: pd.DataFrame) -> dict:
    """
    Retorna dicion√°rio com total e percentuais de cada sentimento.
    Inclui automaticamente todos os sentimentos encontrados no DataFrame.
    """
    if df.empty or "sentiment" not in df.columns:
        return {
            "total": 0,
            "positivo": 0.0,
            "negativo": 0.0,
            "neutro": 0.0,
            "n√£o aplic√°vel": 0.0
        }
    
    # Normaliza os sentimentos usando a fun√ß√£o existente
    s = coerce_sentiment_series(df["sentiment"])
    total = int(len(s))
    
    if total == 0:
        return {
            "total": 0,
            "positivo": 0.0,
            "negativo": 0.0,
            "neutro": 0.0,
            "n√£o aplic√°vel": 0.0
        }
    
    # Conta cada sentimento
    sentiment_counts = s.value_counts().to_dict()
    
    # Calcula percentuais
    result = {"total": total}
    
    # Lista de sentimentos esperados (pode adicionar mais se necess√°rio)
    expected_sentiments = ["positivo", "negativo", "neutro", "n√£o aplic√°vel"]
    
    for sentiment in expected_sentiments:
        count = sentiment_counts.get(sentiment, 0)
        percentage = round(100.0 * count / total, 1)
        result[sentiment] = percentage
    
    # Adiciona qualquer outro sentimento n√£o esperado que apare√ßa nos dados
    for sentiment, count in sentiment_counts.items():
        if sentiment not in expected_sentiments:
            percentage = round(100.0 * count / total, 1)
            result[sentiment] = percentage
    
    # Verifica se a soma est√° pr√≥xima de 100% (pode haver pequenas diferen√ßas por arredondamento)
    total_percentage = sum(v for k, v in result.items() if k != "total")
    
    return result


# Vers√£o alternativa mantendo a assinatura original (tuple) mas com 4 valores:
def sentiment_percentages_tuple(df: pd.DataFrame) -> tuple[int, float, float, float, float]:
    """
    Retorna (total, %pos, %neg, %neu, %nao_aplicavel).
    """
    if df.empty or "sentiment" not in df.columns:
        return 0, 0.0, 0.0, 0.0, 0.0
    
    s = coerce_sentiment_series(df["sentiment"])
    total = int(len(s))
    
    if total == 0:
        return 0, 0.0, 0.0, 0.0, 0.0
    
    pos = int((s == "positivo").sum())
    neg = int((s == "negativo").sum())
    neu = int((s == "neutro").sum())
    nao_aplic = int((s == "n√£o aplic√°vel").sum())
    
    f = lambda x: round(100.0 * x / max(1, total), 1)
    
    return total, f(pos), f(neg), f(neu), f(nao_aplic)

def render_sentiment_cards(df: pd.DataFrame):
    # Agora usando a vers√£o com 5 valores que inclui n√£o aplic√°vel
    total, ppos, pneg, pneu, pna = sentiment_percentages_tuple(df)
    if total == 0:
        return html.Div(className="muted-box", children="Sem dados de sentimento nesta sele√ß√£o.")

    def _kpi_card(title, value, color):
        return dbc.Card(
            dbc.CardBody([
                html.Div(title, className="text-muted", style={"fontSize":"0.85rem"}),
                html.H3(f"{value:.1f}%", className="mb-0", style={"fontWeight":700}),
            ]),
            className="dash-card",
            style={"borderLeft": f"4px solid {color}"}
        )

    # Badges para neutro e N/A lado a lado
    neutro_badge = dbc.Badge(f"Neutro: {pneu:.1f}%", color="secondary", className="ms-2")
    na_badge = dbc.Badge(f"N/A: {pna:.1f}%", color="secondary", className="ms-2")

    return dbc.Row([
        dbc.Col(_kpi_card("üëç Positivo", ppos, "#10B981"), md=6),
        dbc.Col(_kpi_card("üëé Negativo", pneg, "#EF4444"), md=6),
        html.Div([neutro_badge, na_badge], className="mt-2")
    ], className="mb-3")

def topics_bar_fig(sub_df: pd.DataFrame) -> go.Figure:
    if sub_df.empty or "topic" not in sub_df.columns:
        return go.Figure()
    s = _clean_series_for_counts(sub_df["topic"])
    if s.empty:
        return go.Figure()
    vc = s.value_counts()
    total = int(vc.sum())
    df = pd.DataFrame({"topic": vc.index, "Qtde": vc.values})
    df["%"] = (df["Qtde"] / max(1, total) * 100).round(1)
    fig = px.bar(df.head(50), x="topic", y="Qtde", text="%", title="T√≥picos ‚Äì Distribui√ß√£o")
    fig.update_traces(texttemplate="%{text:.1f}%")
    return create_fig_style(fig, x="T√≥pico", y="Qtde", tickangle=-25)

def answers_top_tokens_fig(sub_df: pd.DataFrame, top_n: int = 20) -> Optional[go.Figure]:
    if sub_df.empty or "answer" not in sub_df.columns: return None
    s = sub_df["answer"].dropna().astype(str).str.lower()
    if s.empty: return None
    tokens, rx = [], re.compile(r"\b[^\W\d_]{3,}\b", flags=re.UNICODE)
    for text in s: tokens.extend(rx.findall(text))
    stop = {
        "que","com","para","uma","numa","n√£o","sim","de","da","do","das","dos","em","no","na","os","as","o","a","e",
        "√©","se","por","um","uns","uma","umas","ao","√†","√†s","aos","foi","ser","esta","este","esse","isso","isto",
        "t√°","est√°","pra","pro","mais","menos","muito","pouco","the","and","for","with","you","not","are","your",
        "this","that","was","have","has","had","from","into","about","out","her","his","their","our"
    }
    tokens = [t for t in tokens if t not in stop]
    if not tokens: return None
    vc = pd.Series(tokens).value_counts().head(top_n)
    fig = px.bar(x=vc.index, y=vc.values, title="Palavras mais frequentes (campo aberto)")
    return create_fig_style(fig, x="Palavra", y="Ocorr√™ncias", tickangle=-25)

# ==============================
# 6) Cria√ß√£o do App Dash + CSS
# ==============================
BASE_PATH = os.getenv("BASE_PATH", "/dataviz-svc/")
if not BASE_PATH.startswith("/"):
    BASE_PATH = "/" + BASE_PATH
if not BASE_PATH.endswith("/"):
    BASE_PATH = BASE_PATH + "/"

ASSETS_URL_PATH = BASE_PATH.rstrip("/") + "/assets"

print(f"[BOOT] BASE_PATH={BASE_PATH} | ASSETS_URL_PATH={ASSETS_URL_PATH}")

from flask import Flask
from werkzeug.middleware.proxy_fix import ProxyFix
server = Flask(__name__)

server.wsgi_app = ProxyFix(
    server.wsgi_app,
    x_for=1, x_proto=1, x_host=1, x_port=1, x_prefix=1
)

app = dash.Dash(
    __name__,
    server=server,
    url_base_pathname=BASE_PATH,
    external_stylesheets=[dbc.themes.BOOTSTRAP],
    suppress_callback_exceptions=True,
    assets_url_path=ASSETS_URL_PATH,
    serve_locally=True,
)

# OPCIONAL: Habilite para debug (desabilite em produ√ß√£o)
#app.enable_dev_tools(
#    debug=True,
#    dev_tools_props_check=True,
#    dev_tools_silence_routes_logging=False,
#)

app.index_string = """
<!DOCTYPE html>
<html>
  <head>
    {%metas%}
    <title>Analytics Dashboard</title>
    {%favicon%}
    {%css%}
<style>
  @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;700&display=swap');
  :root{
    --brand:#FF9800;
    --ink:#111111;
    --muted:#6c757d;
    --page-bg:#F7F7F7;
    --card-bg:#FFFFFF;
    --line:#ECECEC;
    --success:#16A34A;
    --danger:#EF4444;
  }
  *{box-sizing:border-box}
  body{
    background:var(--page-bg);
    color:var(--ink);
    font-family:'Poppins',system-ui,-apple-system,Segoe UI,Roboto,'Helvetica Neue',Arial,sans-serif;
  }
  .navbar { border-bottom:1px solid var(--line); background:var(--card-bg); }
  .nav-tabs .nav-link{
    border-radius:12px 12px 0 0;
    font-weight:600; color:var(--muted);
    border:none; padding:12px 24px;
  }
  .nav-tabs .nav-link.active{
    background:var(--card-bg); color:var(--ink);
    border-bottom:3px solid var(--brand) !important;
  }
  .nav-tabs .nav-link:hover{ color:var(--ink) }
  .dash-card{
    background:var(--card-bg);
    border-radius:16px;
    border:1px solid var(--line);
    box-shadow:0 2px 10px rgba(0,0,0,.05);
    transition: box-shadow .2s ease, transform .05s ease;
  }
  .dash-card:hover{ box-shadow:0 4px 16px rgba(0,0,0,.08) }
  .ctrl-grid{
    display:grid;
    grid-template-columns:repeat(3,minmax(0,1fr));
    gap:16px; margin-bottom:12px;
  }
  @media (max-width: 992px){ .ctrl-grid{grid-template-columns:1fr} }
  label{ font-size:.9rem; margin-bottom:6px; color:#374151; }
  .btn{
    border-radius:999px; font-weight:600;
    border:1.5px solid var(--brand);
    background:#fff; color:var(--ink);
  }
  .btn:hover{ box-shadow:0 4px 12px rgba(0,0,0,.08) }
  .btn:active{ transform:translateY(1px) }
  .btn-primary{
    background:var(--brand); border-color:var(--brand); color:var(--ink);
  }
  .badge{ border-radius:999px; }
  .text-muted{ color:var(--muted)!important; }
  .muted-box{
    display:flex; align-items:center; gap:6px;
    padding:16px; border:1px dashed var(--line);
    border-radius:12px; color:var(--muted);
    background:#FAFAFA;
  }
</style>
  </head>
  <body>
    {%app_entry%}
    <footer>
      {%config%}
      {%scripts%}
      {%renderer%}
    </footer>
  </body>
</html>
"""

server = app.server

health_path = (BASE_PATH.rstrip("/") + "/health") if BASE_PATH != "/" else "/health"

@server.route("/health")
def health_root():
    return {"status": "ok", "service": "dataviz-svc"}, 200

@server.route(health_path)
def health_base():
    return {"status": "ok", "service": "dataviz-svc"}, 200

# Navbar
header = dbc.Navbar()

# Tabs
tabs = dbc.Tabs(
    [
        dbc.Tab(label="An√°lise por Pergunta", tab_id="questions"),
        dbc.Tab(label="An√°lises personalizadas", tab_id="pivot"),
        dbc.Tab(label="Dados Brutos", tab_id="raw"),
    ], id="main-tabs", active_tab="questions"
)

# Modal de drill (Pivot)
modal_drill = dbc.Modal([
    dbc.ModalHeader(dbc.ModalTitle(id="pv-drill-title")),
    dbc.ModalBody(id="pv-drill-content"),
], id="pv-drill-modal", size="xl", is_open=False)

app.layout = dbc.Container([
    header,
    dcc.Location(id="url", refresh=False),
    dcc.Store(id="current-env"),
    dcc.Store(id="current-key"),
    tabs,
    html.Div(id="tab-content", className="mt-3"),
], fluid=True)

# ==============================
# 7) UI: Card por Pergunta
# ==============================
def question_card(qid: str, qdesc: str, allowed_cols: List[str], df: pd.DataFrame,
                  env_resolved: str, key: str) -> dbc.Col:
    try:
        series = df.loc[df["question_id"].astype(str) == str(qid), "answer"]
        qtype_meta = get_qtype_for_question_with_meta(env_resolved, qid, series, key)
    except Exception:
        qtype_meta = None

    type_badge = {
        "numeric":         ("üî¢", "primary",  "Num√©rica"),
        "single-choice":   ("üó≥Ô∏è", "success",  "Categ√≥rica"),
        "multiple-choice": ("‚òëÔ∏è", "info",     "M√∫ltipla escolha"),
        "open-ended":      ("üí¨", "warning",  "Campo aberto"),
    }.get(qtype_meta, ("‚ùì", "secondary", "Desconhecido"))

    seg_opts = [{"label": c, "value": c} for c in (allowed_cols or [])]

    controls = html.Div([
        html.Div(className="ctrl-grid", children=[
            html.Div([
                html.Label("Vari√°veis", className="fw-bold"),
                dcc.Dropdown(
                    id={"type": "q-segcol", "qid": qid},
                    options=seg_opts,
                    placeholder="Escolha coluna...",
                    clearable=True
                ),
            ]),
            html.Div([
                html.Label("Valores (opcional)", className="fw-bold"),
                dcc.Dropdown(
                    id={"type": "q-segvals", "qid": qid},
                    multi=True,
                    placeholder="Todos os valores",
                    clearable=True,
                    maxHeight=320,
                    optionHeight=32
                ),
            ]),
        ])
    ])

    return dbc.Col(
        dbc.Card([
            dbc.CardHeader([
                html.Div([
                    html.Div([
                        html.Strong(str(qid), className="me-2"),
                        dbc.Badge(type_badge[0] + " " + type_badge[2],
                                  color=type_badge[1], className="me-2"),
                        html.Div(id={"type": "q-filterpill", "qid": qid},
                                 style={"display": "inline-block"}),
                    ], style={"display": "flex", "alignItems": "center", "gap": "8px"}),
                    html.P(qdesc or "", className="text-muted mb-0 mt-2",
                           style={"fontSize": "0.9rem"}),
                ], style={"flex": "1"}),
            ]),

            dbc.CardBody([
                dcc.Store(id={"type":"q-filter","qid": qid}, data={"category": None, "topic": None}),
                dcc.Store(id={"type":"q-drill","qid": qid},  data={"level": 0, "seg_value": None, "category": None}),

                html.Div([
                    dbc.Button("üîç Filtros", id={"type":"q-collapse-btn","qid": qid}, color="light", size="sm", className="mb-3"),
                    dbc.Collapse(controls, id={"type":"q-collapse","qid": qid}, is_open=False),
                ]),

                dbc.Button("üóëÔ∏è Limpar filtros", id={"type":"q-clear","qid": qid}, size="sm", color="secondary", outline=True,
                        className="mb-3", style={"display": "none"}),

                # ‚ñ∂Ô∏è Cards de sentimento ficam aqui
                html.Div(id={"type":"q-sentcards","qid": qid}, className="mb-3"),

                # Gr√°fico principal, que vamos ocultar em perguntas abertas
                html.Div(id={"type":"q-fig-wrap","qid": qid},
                        children=dcc.Loading(dcc.Graph(id={"type":"q-fig","qid": qid}, config={"displayModeBar": False}), type="dot")),


                dcc.Graph(id={"type": "q-catfig", "qid": qid},
                          config={"displayModeBar": False},
                          style={"marginTop": "12px"}),

                dcc.Graph(id={"type": "q-topicsfig", "qid": qid},
                          config={"displayModeBar": False},
                          style={"marginTop": "12px"}),

                dcc.Graph(id={"type": "q-answers", "qid": qid},
                          config={"displayModeBar": False},
                          style={"marginTop": "12px", "display": "none"}),
            ])
        ], className="mb-4 dash-card"),
        md=6
    )

# ==============================
# 8) Pivot (An√°lises personalizadas)
# ==============================
def to_date_str(x):
    try:
        if x is None or (hasattr(pd, "isna") and pd.isna(x)):
            return None
        return pd.to_datetime(x, errors="coerce").date().isoformat()
    except Exception:
        return None
 
def pivot_controls(df: pd.DataFrame, state: Dict):
    """UI da aba Pivot ‚Äì cart√µes do mesmo tamanho, pergunta1 e sentiment pr√©-selecionados."""
    if df.empty:
        return empty_state("Sem dados para montar a pivot.")

    # colunas num√©ricas para m√©tricas
    numeric_cols = sorted([
        c for c in df.columns
        if c not in NON_SEGMENTABLE and not is_pii(c)
        and pd.to_numeric(df[c], errors="coerce").notna().mean() > 0.7
    ])

    # dimens√µes seguras
    dims_base = (state.get("ALLOWED_SEGMENT_COLS") or []) + ["sentiment", "category", "topic"]
    dims = sorted(list(set([c for c in dims_base if c not in numeric_cols])))
    dims_options = [{"label": c, "value": c} for c in dims] + [
        {"label": "Resposta (da pergunta selecionada)", "value": "__pv_answer__"}
    ]

    # perguntas e default = primeira (pergunta1)
    qdf = state.get("questions_df")
    if qdf is None or (hasattr(qdf, "empty") and qdf.empty):
        qdf = pd.DataFrame(columns=["question_id", "question_description"])

    def _label_for_row(row):
        qd = row.get("question_description")
        if pd.isna(qd) or str(qd).strip().lower() in {"", "nan", "none", "null"}:
            return str(row["question_id"])
        return str(qd)[:120]

    q_opts = [{"label": _label_for_row(r), "value": str(r["question_id"])}
              for _, r in qdf.iterrows()]
    default_qid = q_opts[0]["value"] if q_opts else None

    stats_local = state.get("stats", {})
    CARD_HEIGHT = 420  # px

    return dbc.Card([
        dbc.CardHeader(html.H5("üß≠ Pivot (tabela din√¢mica + gr√°fico)", className="mb-0")),
        dbc.CardBody([
            html.Div(className="ctrl-grid", children=[
                html.Div([
                    html.Label("Pergunta para explorar respostas (opcional)", className="fw-bold"),
                    dcc.Dropdown(id="pv-qid", options=q_opts, value=default_qid,
                                 placeholder="Selecione a pergunta‚Ä¶")
                ]),
                html.Div([
                    html.Label("Usar respostas como dimens√£o", className="fw-bold"),
                    dcc.Checklist(
                        id="pv-use-answer",
                        options=[{"label": "Adicionar 'Resposta (da pergunta)' √†s dimens√µes", "value": "on"}],
                        value=["on"], inputStyle={"marginRight": "6px"}
                    )
                ]),
                html.Div([
                    html.Label("Binning para respostas num√©ricas", className="fw-bold"),
                    dcc.RadioItems(
                        id="pv-answer-binning",
                        options=[{"label": "5 faixas", "value": "5"},
                                 {"label": "10 faixas", "value": "10"},
                                 {"label": "20 faixas", "value": "20"}],
                        value="10", inline=True
                    )
                ]),
            ]),
            html.Div(className="ctrl-grid", children=[
                html.Div([
                    html.Label("Linhas (index)", className="fw-bold"),
                    dcc.Dropdown(
                        id="pv-rows", options=dims_options, multi=True,
                        value=["sentiment"],  # default para n√£o ficar vazio
                        placeholder="Escolha 1‚Äì2 dimens√µes‚Ä¶"
                    )
                ]),
                html.Div([
                    html.Label("Colunas (columns)", className="fw-bold"),
                    dcc.Dropdown(id="pv-cols", options=dims_options, multi=False, placeholder="(opcional)")
                ]),
                html.Div([
                    html.Label("M√©trica", className="fw-bold"),
                    dcc.Dropdown(
                        id="pv-metric",
                        options=([{"label": "Contagem de respostas", "value": "__count__"}] +
                                 [{"label": c, "value": c} for c in numeric_cols]),
                        value="__count__"
                    )
                ]),
            ]),
            html.Div(className="ctrl-grid", children=[
                html.Div([
                    html.Label("Agrega√ß√£o", className="fw-bold"),
                    dcc.RadioItems(
                        id="pv-agg",
                        options=[{"label":"Soma","value":"sum"},
                                 {"label":"M√©dia","value":"mean"},
                                 {"label":"Mediana","value":"median"},
                                 {"label":"M√≠n","value":"min"},
                                 {"label":"M√°x","value":"max"}],
                        value="sum", inline=True)
                ]),
                html.Div([
                    html.Label("Tipo de gr√°fico", className="fw-bold"),
                    dcc.RadioItems(
                        id="pv-chart",
                        options=[{"label":"Barras","value":"bar"},
                                 {"label":"Heatmap","value":"heatmap"}],
                        value="bar", inline=True)
                ]),
                html.Div([
                    html.Label("Filtro de per√≠odo", className="fw-bold"),
                    dcc.DatePickerRange(
                        id="pv-daterange",
                        start_date=to_date_str(stats_local.get("start")),
                        end_date=to_date_str(stats_local.get("end")),
                        display_format="DD/MM/YYYY",
                        className="w-100"
                    )
                ]),
            ]),
            html.Div(className="ctrl-grid", children=[
                html.Div([
                    html.Label("Filtrar por dimens√£o (opcional)", className="fw-bold"),
                    dcc.Dropdown(
                        id="pv-dim-filter-col",
                        options=[], placeholder="Escolha uma dimens√£o de Linhas/Colunas",
                        clearable=True
                    ),
                ]),
                html.Div([
                    html.Label("Valores da dimens√£o", className="fw-bold"),
                    dcc.Dropdown(
                        id="pv-dim-filter-values",
                        options=[], multi=True,
                        placeholder="Selecione 1+ valores‚Ä¶",
                        clearable=True, maxHeight=320, optionHeight=32
                    ),
                ]),
                html.Div(),
            ]),
            dbc.Row([
                dbc.Col(
                    dbc.Card([
                        dbc.CardHeader("Tabela Din√¢mica"),
                        dbc.CardBody(
                            id="pv-out-table",
                            style={"maxHeight": f"{CARD_HEIGHT}px", "overflowY": "auto"}
                        )
                    ], style={"height": "100%"}), md=4
                ),
                dbc.Col(
                    dbc.Card([
                        dbc.CardHeader("Nuvem de t√≥picos (din√¢mica)"),
                        dbc.CardBody(
                            id="pv-topics-cloud",
                            style={"height": f"{CARD_HEIGHT}px",
                                   "display": "flex", "alignItems": "center", "justifyContent": "center"}
                        )
                    ], style={"height": "100%"}), md=4
                ),
                dbc.Col(
                    dbc.Card([
                        dbc.CardHeader("Gr√°fico (clique nas barras para ver respostas)"),
                        dbc.CardBody(
                            dcc.Loading(
                                dcc.Graph(id="pv-out-chart-graph",
                                          style={"height": f"{CARD_HEIGHT}px"},
                                          config={"displayModeBar": False}),
                                type="dot"))
                    ], style={"height": "100%"}), md=4
                ),
            ], className="g-3 align-items-stretch"),
            modal_drill
        ])
    ], className="mb-4 dash-card")


# ==============================
# 9) Callbacks ‚Äì Captura ENV e KEY da URL
# ==============================
from urllib.parse import parse_qs

@dash.callback(
    Output("current-env", "data"),
    Input("url", "search"),
    prevent_initial_call=False
)
def set_current_env(search):
    default_env = normalize_env(os.getenv("APP_DEFAULT_ENV", "dev"))
    env = default_env
    if search and "env=" in search:
        qs = parse_qs(search.lstrip("?"))
        env = normalize_env((qs.get("env", [default_env]) or [default_env])[0])
    return env

@dash.callback(
    Output("current-key", "data"),
    Input("url", "search"),
    prevent_initial_call=False
)
def set_current_key(search):
    default_key = os.getenv("KEY", "")
    key = default_key
    if search and "key=" in search:
        qs = parse_qs(search.lstrip("?"))
        key = (qs.get("key", [default_key]) or [default_key])[0]
    return key


# ==============================
# 10) Callbacks ‚Äì Pivot principal
# ==============================

@dash.callback(
  Output("pv-out-table","children"),
  Output("pv-out-chart-graph","figure"),
  Output("pv-topics-cloud","children"),
  Input("pv-rows","value"),
  Input("pv-cols","value"),
  Input("pv-metric","value"),
  Input("pv-agg","value"),
  Input("pv-chart","value"),
  Input("pv-daterange","start_date"),
  Input("pv-daterange","end_date"),
  Input("pv-qid","value"),
  Input("pv-use-answer","value"),
  Input("pv-answer-binning","value"),
  Input("pv-dim-filter-col","value"),
  Input("pv-dim-filter-values","value"),
  Input("current-key","data"),
  Input("current-env","data"),
)

def update_pivot(rows, cols, metric, agg, chart, ds, de, pv_qid, pv_use_answer, pv_bins,
                 dim_filter_col, dim_filter_vals, key, env_resolved):
    try:
        key = key or os.getenv("KEY","")
        env_resolved = normalize_env(env_resolved or os.getenv("APP_DEFAULT_ENV","dev"))

        df = load_df_for_key(env_resolved, key) if key else pd.DataFrame()
        if df.empty:
            return empty_state("Sem dados."), go.Figure(), empty_state("Sem dados.")
        d = df.copy()

        # per√≠odo
        if ds and de and "date_of_response" in d.columns:
            d = d[(d["date_of_response"] >= ds) & (d["date_of_response"] <= de)]

        # normaliza sele√ß√£o
        rows = rows if isinstance(rows, list) else ([rows] if rows else [])
        if not rows:
            return empty_state("Escolha ao menos 1 dimens√£o em Linhas."), go.Figure(), empty_state("Escolha ao menos 1 dimens√£o.")

        # se uma pergunta foi escolhida, restringe DF e (se aplic√°vel) cria __pv_answer__
        base_qtype = None
        wants_answer_dim = pv_use_answer and ("on" in (pv_use_answer or []))
        if pv_qid:
            d = d[d["question_id"].astype(str) == str(pv_qid)].copy()
            if d.empty:
                return empty_state("A pergunta selecionada n√£o possui dados no per√≠odo/recorte atual."), go.Figure(), empty_state("Sem dados para nuvem.")
            base_qtype = get_qtype_for_question_with_meta(env_resolved, pv_qid, d["answer"], key)
            if wants_answer_dim and base_qtype != "text":
                try:
                    bins = int(pv_bins) if str(pv_bins) in {"5","10","20"} else 10
                except Exception:
                    bins = 10
                d = make_pv_answer(d, bins=bins)

        # filtro por dimens√£o (apenas se a coluna existe ap√≥s poss√≠veis explodes/cuts)
        if dim_filter_col and dim_filter_vals and dim_filter_col in d.columns:
            chosen = dim_filter_vals if isinstance(dim_filter_vals, list) else [dim_filter_vals]
            d = d[d[dim_filter_col].astype(str).isin([str(v) for v in chosen])]

        # garante que __pv_answer__ existe quando solicitado nas dimens√µes
        if ("__pv_answer__" in rows or cols == "__pv_answer__") and "__pv_answer__" not in d.columns:
            return empty_state("Ative 'Usar respostas como dimens√£o' e selecione a pergunta."), go.Figure(), empty_state("Selecione a pergunta para a nuvem.")

        # m√©trica
        if metric == "__count__":
            d["__count__"] = 1
            val, aggfunc = "__count__", "sum"
        else:
            d[metric] = pd.to_numeric(d[metric], errors="coerce")
            val, aggfunc = metric, (agg or "mean")

        # pivot
        piv = pd.pivot_table(
            d, index=rows, columns=cols,
            values=val, aggfunc=aggfunc, fill_value=0, dropna=False
        )

        # >>> RENOMEIA COLUNAS S√ì PARA EXIBI√á√ÉO
        piv_disp = (
            piv.reset_index()
               .rename(columns={"__count__": "#", "__pv_answer__": "Respostas"})
        )

        table = dbc.Table.from_dataframe(
            piv_disp.head(500), striped=True, bordered=False, hover=True,
            size="sm", responsive=True
        )

        fig = go.Figure()
        if chart == "bar":
            if cols:
                piv_m = piv.reset_index().melt(id_vars=rows, var_name=cols, value_name="value")
                x = rows[-1]
                x_title = "Respostas" if x == "__pv_answer__" else "Dimens√£o"
                fig = px.bar(piv_m, x=x, y="value", color=cols, barmode="group", title="Pivot ‚Äì Barras")
                fig.update_traces(text=piv_m["value"], textposition="outside", cliponaxis=False)
                fig = create_fig_style(fig, x=x_title, y="")
                fig.update_yaxes(showticklabels=False)  # remove r√≥tulos do eixo Y
                fig = responsive_axis(fig, labels=piv_m[x].unique().tolist())
            else:
                piv_s = piv.reset_index()
                x = rows[-1]
                x_title = "Respostas" if x == "__pv_answer__" else "Dimens√£o"
                val_cols = [c for c in piv_s.columns if c not in rows]
                ycol = val_cols[0] if val_cols else None
                if ycol:
                    fig = px.bar(piv_s, x=x, y=ycol, title="Pivot ‚Äì Barras")
                    fig.update_traces(text=piv_s[ycol], textposition="outside", cliponaxis=False)
                    fig = create_fig_style(fig, x=x_title, y="")
                    fig.update_yaxes(showticklabels=False)  # remove r√≥tulos do eixo Y
                    fig = responsive_axis(fig, labels=piv_s[x].unique().tolist())
                else:
                    fig = go.Figure()
        else:
            if cols and len(rows) == 1:
                hm = piv.copy()
                fig = px.imshow(hm, labels=dict(x=cols, y=(rows[0] if rows else ""), color="Valor"),
                                title="Pivot ‚Äì Heatmap")
            else:
                fig = go.Figure()

        fig.update_yaxes(showticklabels=False)

        # Mostra a nuvem sempre que a pergunta for campo aberto
        if pv_qid and (base_qtype in {"open-ended", "text"}):
            cloud_child = build_topics_wordcloud_component(d)  # usa a coluna 'topic'
        else:
            cloud_child = empty_state("Dispon√≠vel apenas para perguntas de texto livre.")

        return table, fig, cloud_child

    except Exception as e:
        app.server.logger.exception("Erro no callback update_pivot")
        return _error_box("Erro no callback update_pivot", e), go.Figure(), _error_box("Erro", e)


@dash.callback(
    Output("pv-dim-filter-col", "options"),
    Output("pv-dim-filter-col", "value"),
    Input("pv-rows", "value"),
    Input("pv-cols", "value"),
)
def sync_dim_filter_col(rows, cols):
    rows = rows if isinstance(rows, list) else ([rows] if rows else [])
    cols = cols if isinstance(cols, list) else ([cols] if cols else [])
    dims = [c for c in rows + cols if c]
    dims = list(dict.fromkeys(dims))
    return [{"label": c, "value": c} for c in dims], None

@dash.callback(
    Output("pv-dim-filter-values", "options"),
    Output("pv-dim-filter-values", "value"),
    Input("pv-dim-filter-col", "value"),
    Input("pv-qid", "value"),
    Input("pv-use-answer", "value"),
    Input("pv-answer-binning", "value"),
    Input("pv-daterange", "start_date"),
    Input("pv-daterange", "end_date"),
    Input("current-key","data"),
    Input("current-env","data"),
)
def sync_dim_filter_values(dim_col, pv_qid, pv_use_answer, pv_bins, ds, de, key, env_resolved):
    key = key or os.getenv("KEY","")
    env_resolved = normalize_env(env_resolved or "dev")

    df = load_df_for_key(env_resolved, key) if key else pd.DataFrame()

    if not dim_col or df.empty:
        return [], None

    d = df.copy()
    if ds and de and "date_of_response" in d.columns:
        d = d[(d["date_of_response"] >= ds) & (d["date_of_response"] <= de)]

    if pv_qid:
        d = d[d["question_id"].astype(str) == str(pv_qid)].copy()
        qtype = analyze_qtype(d["answer"]) if not d.empty else None
        wants_answer_dim = pv_use_answer and ("on" in (pv_use_answer or []))
        if wants_answer_dim and qtype != "text":
            try:
                bins = int(pv_bins) if str(pv_bins) in {"5","10","20"} else 10
            except Exception:
                bins = 10
            d = make_pv_answer(d, bins=bins)
        if dim_col == "__pv_answer__" and "__pv_answer__" not in d.columns:
            return [], None

    if dim_col not in d.columns:
        return [], None

    vals = (d[dim_col].dropna().astype(str).str.strip()
            .loc[lambda s: s.ne("") & ~s.str.lower().isin({"nan","none","null"})]
            .unique().tolist())
    vals.sort()
    return [{"label": v, "value": v} for v in vals], None


# ==============================
# 11) Renderiza√ß√£o das Abas
# ==============================
@dash.callback(
    Output("tab-content", "children"),
    Input("main-tabs", "active_tab"),
    Input("current-key", "data"),
    Input("current-env", "data"),
    prevent_initial_call=False
)
def render_tab(active, key, env_resolved):
    try:
        key = key or os.getenv("KEY", "")
        env_resolved = normalize_env(env_resolved or "dev")

        try:
            df = load_df_for_key(env_resolved, key) if key else pd.DataFrame()
        except Exception as e:
            msg = f"Erro ao carregar CUBE para env={env_resolved} key={key}: {e}"
            print("[render_tab]", msg)
            return html.Div(msg, className="alert alert-danger")

        state = build_state(df, env_resolved=env_resolved, key=key)

        if df.empty:
            return html.Div("Estamos aguardando dados para gerar insights sobre seu caso de uso...", className="alert alert-warning")

        if active == "questions":
            cards = [
                question_card(
                    r["question_id"],
                    r["question_description"],
                    state["ALLOWED_SEGMENT_COLS"],
                    df,
                    env_resolved,
                    key
                )
                for _, r in state["questions_df"].iterrows()
            ]
            return dbc.Row(cards) if cards else empty_state("Sem perguntas para exibir.")

        if active == "pivot":
            try:
                ui = pivot_controls(df, state)
                return html.Div([ui])
            except Exception as e:
                import traceback
                print("[pivot_controls ERROR]", repr(e))
                traceback.print_exc()
                return html.Div(f"Erro ao montar Pivot: {e}", className="alert alert-danger")

        if active == "raw":
            cols_show = [c for c in df.columns if c not in {"orig_answer","survey_id"} and not is_pii(c)]
            if "respondent_id" in cols_show:
                cols_show = ["respondent_id"] + [c for c in cols_show if c != "respondent_id"]
            return html.Div([
                html.H5("üìã Dados brutos"),
                raw_controls(df),
                html.Div(id="raw-table")
            ])

        return html.Div("Selecione uma aba.", className="text-muted")
    
    except Exception as e:
        app.server.logger.exception("Erro no callback render_tab")
        return _error_box("Erro no callback render_tab", e)


# ==============================
# 12) Callbacks de UX e Drill por Pergunta
# ==============================
@dash.callback(
    Output({"type":"q-collapse","qid":MATCH}, "is_open"),
    Input({"type":"q-collapse-btn","qid":MATCH}, "n_clicks"),
    State({"type":"q-collapse","qid":MATCH}, "is_open"),
    prevent_initial_call=True
)
def toggle_collapse(n, is_open):
    if n:
        return not is_open
    return is_open

@dash.callback(
    Output({"type":"q-segvals","qid":MATCH}, "options"),
    Output({"type":"q-segvals","qid":MATCH}, "value"),
    Input({"type":"q-segcol","qid":MATCH}, "value"),
    Input("current-key","data"),
    Input("current-env","data"),
)
def update_seg_values_per_q(seg_col, key, env_resolved):
    key = key or os.getenv("KEY","")
    env_resolved = normalize_env(env_resolved or "dev")
    df = load_df_for_key(env_resolved, key) if key else pd.DataFrame()

    if not seg_col or df.empty or seg_col not in df.columns:
        return [], None
    vals = sorted(df[seg_col].dropna().astype(str).unique().tolist())
    return [{"label": v, "value": v} for v in vals], None

@dash.callback(
    Output({"type":"q-filter","qid":MATCH}, "data"),
    Input({"type":"q-catfig","qid":MATCH}, "clickData"),
    Input({"type":"q-topicsfig","qid":MATCH}, "clickData"),
    Input({"type":"q-clear","qid":MATCH}, "n_clicks"),
    State({"type":"q-filter","qid":MATCH}, "data"),
    prevent_initial_call=True
)
def sync_qfilter(cat_click, topic_click, clear_clicks, current):
    current = current or {"category": None, "topic": None}
    ctx = dash.callback_context
    if not ctx.triggered:
        return current
    prop = ctx.triggered[0]["prop_id"]

    if prop.endswith(".n_clicks"):
        return {"category": None, "topic": None}

    if '"q-catfig"' in prop and prop.endswith(".clickData"):
        label = _extract_click_label(cat_click)
        if not label:
            return current
        return {"category": None if current.get("category") == str(label) else str(label), "topic": None}

    if '"q-topicsfig"' in prop and prop.endswith(".clickData"):
        label = _extract_click_label(topic_click)
        if not label:
            return current
        return {"category": None, "topic": None if current.get("topic") == str(label) else str(label)}

    return current

@dash.callback(
    Output({"type":"q-drill","qid":MATCH}, "data"),
    Input({"type":"q-fig","qid":MATCH}, "clickData"),
    Input({"type":"q-catfig","qid":MATCH}, "clickData"),
    Input({"type":"q-clear","qid":MATCH}, "n_clicks"),
    State({"type":"q-drill","qid":MATCH}, "data"),
    State({"type":"q-fig","qid":MATCH}, "id"),
    prevent_initial_call=True
)
def update_drill_state(main_click, cat_click, clear_clicks, curr, fig_id):
    curr = curr or {"level":0, "sentiment":None, "category":None}
    ctx = dash.callback_context
    if not ctx.triggered:
        return curr
    prop = ctx.triggered[0]["prop_id"]

    if prop.endswith(".n_clicks"):
        return {"level":0, "sentiment":None, "category":None}

    if '"q-fig"' in prop and prop.endswith(".clickData"):
        label = _extract_click_label(main_click)
        if not label:
            return curr
        if str(curr.get("sentiment")) == str(label) and (curr.get("level") or 0) >= 1:
            return {"level":0, "sentiment":None, "category":None}
        return {"level":1, "sentiment":str(label), "category":None}

    if '"q-catfig"' in prop and prop.endswith(".clickData"):
        label = _extract_click_label(cat_click)
        if not label:
            return curr
        if str(curr.get("category")) == str(label) and (curr.get("level") or 0) >= 2:
            return {"level":1, "sentiment":curr.get("sentiment"), "category":None}
        return {"level":2, "sentiment":curr.get("sentiment"), "category":str(label)}

    return curr

@dash.callback(
    Output({"type":"q-fig","qid":MATCH}, "figure"),
    Output({"type":"q-fig-wrap","qid":MATCH}, "style"),
    Output({"type":"q-catfig","qid":MATCH}, "figure"),
    Output({"type":"q-topicsfig","qid":MATCH}, "figure"),
    Output({"type":"q-answers","qid":MATCH}, "figure"),
    Output({"type":"q-catfig","qid":MATCH}, "style"),
    Output({"type":"q-topicsfig","qid":MATCH}, "style"),
    Output({"type":"q-answers","qid":MATCH}, "style"),
    Output({"type":"q-clear","qid":MATCH}, "style"),
    Output({"type":"q-sentcards","qid":MATCH}, "children"),
    Input({"type":"q-segcol","qid":MATCH}, "value"),
    Input({"type":"q-segvals","qid":MATCH}, "value"),
    Input({"type":"q-filter","qid":MATCH}, "data"),
    Input({"type":"q-drill","qid":MATCH}, "data"),
    State({"type":"q-fig","qid":MATCH}, "id"),
    Input("current-key","data"),
    Input("current-env","data"),
)

def update_question_graph(seg_col, seg_vals, qfilter, qdrill, fig_id, key, env_resolved):
    # 10 sa√≠das SEMPRE
    main_fig   = go.Figure()
    cat_fig    = go.Figure()
    topics_fig = go.Figure()
    answers_fig= go.Figure()

    style_show = {"marginTop":"12px"}
    style_hide = {"display":"none"}

    fig_wrap_style = {"marginTop":"12px"}   # padr√£o: mostrar
    fig_wrap_style = style_show

    cat_style      = style_hide
    topics_style   = style_hide
    answers_style  = style_hide
    clear_style    = {"display":"none"}
    sent_cards     = html.Div()

    try:
        key = key or os.getenv("KEY","")
        env_resolved = normalize_env(env_resolved or "dev")
        df = load_df_for_key(env_resolved, key) if key else pd.DataFrame()

        if not fig_id or "qid" not in fig_id:
            return (main_fig, fig_wrap_style, cat_fig, topics_fig, answers_fig,
                    {"display":"none"}, {"display":"none"}, {"display":"none"},
                    {"display":"none"}, sent_cards)
 
        qid = fig_id["qid"]
        sub_all = df[df["question_id"] == qid].copy()
        sub = sub_all.copy()

        if seg_col and seg_vals and seg_col in sub.columns:
            sub = sub[sub[seg_col].astype(str).isin([str(v) for v in seg_vals])]
        sub = _apply_qfilter(sub, qfilter)

        base_qtype = get_qtype_for_question_with_meta(
            env_resolved,
            qid,
            sub_all["answer"] if "answer" in sub_all.columns else pd.Series(dtype=str),
            key
        )

        meta = load_questionnaire_meta(env_resolved, key)
        opts = (meta.get("options_map", {}) or {}).get(str(qid)) or []

        # --- LIKERT 1‚Äì5 (se houver)
        is_likert = (str(qid) in LIKERT_1_5_IDS) and (base_qtype in {"numeric","categorical","text"})
        if is_likert:
            vals = pd.to_numeric(sub["answer"], errors="coerce").round().clip(1,5).astype("Int64")
            d = sub.assign(val=vals).dropna(subset=["val"])
            cat_order = [1,2,3,4,5]
            labels_15 = [str(i) for i in cat_order]
            vc = d["val"].astype(int).value_counts().reindex(cat_order, fill_value=0)
            main_fig = px.bar(x=labels_15, y=vc.values, title="Distribui√ß√£o (escala 1‚Äì5)")
            main_fig = create_fig_style(main_fig, x="Escala (1‚Äì5)", y="Qtde")
            main_fig.update_traces(text=list(vc.values), textposition="outside", cliponaxis=False)
            main_fig.update_xaxes(showgrid=False, showticklabels=True)
            main_fig.update_yaxes(showgrid=False, showticklabels=True)

            # cards s√≥ para abertas
            sent_cards = render_sentiment_cards(sub) if (base_qtype in {"open-ended","text"}) else html.Div()
            clear_style = {"display":"inline-block","marginBottom":"12px"} if (qfilter and (qfilter.get("category") or qfilter.get("topic"))) else {"display":"none"}

            return (main_fig, fig_wrap_style, cat_fig, topics_fig, answers_fig,
                    cat_style, topics_style, answers_style, clear_style, sent_cards)

        # --- NUM√âRICA
        if base_qtype == "numeric":
            vals = pd.to_numeric(sub["answer"], errors="coerce")
            main_fig = px.histogram(vals.dropna(), nbins=20, title="Distribui√ß√£o")
            main_fig = create_fig_style(main_fig, x="Valor", y="Frequ√™ncia")
            main_fig.update_xaxes(showgrid=False, showticklabels=True)
            main_fig.update_yaxes(showgrid=False, showticklabels=True)

        # --- M√öLTIPLA
        elif base_qtype in ["multiple-choice", "multiple"]:
            sent_cards = html.Div()

            exploded = explode_multiple(sub)
            if not exploded.empty and "answer_item" in exploded.columns:
                # limpeza sem reindex
                exploded["answer_item"] = exploded["answer_item"].astype(str)
                m = _non_empty_mask(exploded["answer_item"])
                exploded = exploded[m].copy()

                if not exploded.empty:
                    vc = exploded["answer_item"].value_counts().head(20)
                    df_bar = pd.DataFrame({"opcao": vc.index.astype(str), "qtde": vc.values})
                    main_fig = px.bar(df_bar, x="opcao", y="qtde", title="Ocorr√™ncias por op√ß√£o")
                    main_fig.update_traces(text=df_bar["qtde"], textposition="outside", cliponaxis=False)
                    main_fig = create_fig_style(main_fig, x="Op√ß√£o", y="Qtde")
                    main_fig = responsive_axis(main_fig, labels=df_bar["opcao"].tolist())
                else:
                    main_fig = make_minimal(go.Figure())
            else:
                main_fig = make_minimal(go.Figure())

            main_fig.update_xaxes(showgrid=False, ticks="")
            main_fig.update_yaxes(showgrid=False, ticks="", showticklabels=False)

        # --- CATEG√ìRICA
        elif base_qtype in ("single-choice", "categorical"):
            sent_cards = html.Div()

            # Tenta na ordem: answer -> orig_answer -> option/choice -> category (fallback duro)
            s, used_col = _first_nonempty_series(
                sub, ["answer", "orig_answer", "option", "choice", "resposta", "category"]
            )
            print(f"[DEBUG] CATEGORICA qid={qid} fonte={used_col} n={len(s)}")

            if not s.empty:
                vc = s.value_counts()

                # respeita op√ß√µes do question√°rio, se existirem
                meta = load_questionnaire_meta(env_resolved, key)
                opts = (meta.get("options_map", {}) or {}).get(str(qid)) or []
                if opts:
                    order = [o for o in opts if o in vc.index]
                    outros = [o for o in vc.index if o not in order]
                    vc = vc.reindex(order + outros)

                vc = vc.head(30)
                df_bar = pd.DataFrame({"opcao": vc.index.astype(str), "qtde": vc.values})
                main_fig = px.bar(
                    df_bar, x="opcao", y="qtde",
                    title="Ocorr√™ncias por op√ß√£o",
                    category_orders={"opcao": df_bar["opcao"].tolist()}
                )
                main_fig.update_traces(text=df_bar["qtde"], textposition="outside", cliponaxis=False)
                main_fig = create_fig_style(main_fig, x="Op√ß√£o", y="Qtde")
                main_fig = responsive_axis(main_fig, labels=df_bar["opcao"].tolist())
            else:
                main_fig = make_minimal(go.Figure())

            main_fig.update_xaxes(showgrid=False, ticks="")
            main_fig.update_yaxes(showgrid=False, ticks="", showticklabels=False)

        elif base_qtype == "open-ended":
            # esconder o gr√°fico principal
            fig_wrap_style = {"display":"none"}
            main_fig = go.Figure()

            # cards de sentimento
            sent_cards = render_sentiment_cards(sub) if not sub.empty else html.Div()


            # ---- NOVO: gr√°fico por CATEGORIA no lugar de "Inten√ß√£o"
            s_cat = sub["category"].dropna().astype(str).str.strip() if "category" in sub.columns else pd.Series([], dtype=str)
            s_cat = s_cat[s_cat.ne("") & ~s_cat.str.lower().isin({"nan", "none", "null"})]

            if not s_cat.empty:
                vc = s_cat.value_counts().head(30)
                df_bar = pd.DataFrame({"Categoria": vc.index.astype(str), "Qtde": vc.values})
                cat_fig = px.bar(df_bar, x="Categoria", y="Qtde", title="Categorias ‚Äì Distribui√ß√£o")
                cat_fig.update_traces(text=df_bar["Qtde"], textposition="outside", cliponaxis=False)
                cat_fig = create_fig_style(cat_fig, x="Categoria", y="Qtde")
                cat_fig = responsive_axis(cat_fig, labels=df_bar["Categoria"].tolist())
                cat_style = {"marginTop": "12px"}
            else:
                cat_fig = go.Figure()
                cat_style = {"display": "none"}

            # Mantemos os outros slots ocultos para n√£o duplicar gr√°fico
            topics_fig = go.Figure()
            topics_style = {"display": "none"}
            answers_fig = go.Figure()
            answers_style = {"display": "none"}

            # Bot√£o "Limpar filtros" quando houver filtro local ou drill
            has_local_filter = bool(qfilter and (qfilter.get("category") or qfilter.get("topic")))
            has_drill = bool((qdrill or {}).get("level", 0) > 0)
            clear_style = {"display": "inline-block", "marginBottom": "12px"} if (has_local_filter or has_drill) else {"display": "none"}

            return (
                main_fig,                     # q-fig
                fig_wrap_style,               # q-fig-wrap style (escondido)
                cat_fig,                      # q-catfig  (AGORA o gr√°fico principal p/ abertas)
                topics_fig,                   # q-topicsfig
                answers_fig,                  # q-answers
                cat_style,                    # style catfig (mostrar/ocultar)
                topics_style,                 # style topicsfig
                answers_style,                # style answersfig
                clear_style,                  # style bot√£o limpar
                sent_cards                    # cards de sentimento
            )

        # Retorno padr√£o para todos os outros tipos (numeric, categorical, multiple)
        # Bot√£o "Limpar filtros" quando houver filtro local
        has_local_filter = bool(qfilter and (qfilter.get("category") or qfilter.get("topic")))
        clear_style = {"display": "inline-block", "marginBottom": "12px"} if has_local_filter else {"display": "none"}

        return (
            main_fig,                     # q-fig
            fig_wrap_style,               # q-fig-wrap style
            cat_fig,                      # q-catfig
            topics_fig,                   # q-topicsfig
            answers_fig,                  # q-answers
            cat_style,                    # style catfig
            topics_style,                 # style topicsfig
            answers_style,                # style answersfig
            clear_style,                  # style bot√£o limpar
            sent_cards                    # cards de sentimento
        )

    except Exception as e:
        app.server.logger.exception("Erro no callback update_question_graph")
        empty = go.Figure()
        error_msg = _error_box("Erro no callback update_question_graph", e)
        return (empty, style_hide, empty, empty, empty,
                style_hide, style_hide, style_hide, {"display":"none"}, error_msg)


@dash.callback(
    Output({"type":"q-filterpill","qid":MATCH}, "children"),
    Input({"type":"q-filter","qid":MATCH}, "data")
)
def show_filter_pill(qfilter):
    if not qfilter:
        return ""
    if qfilter.get("category"):
        return dbc.Badge(f'Categoria: {qfilter["category"]}', color="info", className="me-2")
    if qfilter.get("topic"):
        return dbc.Badge(f'T√≥pico: {qfilter["topic"]}', color="info", className="me-2")
    return ""

@dash.callback(
    Output("raw-table", "children"),
    Input({"type": "raw-filter", "col": ALL}, "value"),
    State({"type": "raw-filter", "col": ALL}, "id"),
    State("current-key", "data"),
    State("current-env", "data"),
    prevent_initial_call=False,
)
def update_raw_table(filter_values, filter_ids, key, env_resolved):
    try:
        # Mapeia colunas => valores escolhidos
        active_filters = {}
        for val, fid in zip(filter_values or [], filter_ids or []):
            col = (fid or {}).get("col")
            if not col:
                continue
            if isinstance(val, list):
                sel = [str(v) for v in val if v not in (None, "")]
            elif val not in (None, ""):
                sel = [str(val)]
            else:
                sel = []
            if sel:
                active_filters[col] = sel

        # carrega DF
        env_resolved = normalize_env(env_resolved or "dev")
        df = load_df_for_key(env_resolved, key or os.getenv("KEY","")) if key or os.getenv("KEY","") else pd.DataFrame()

        if df.empty:
            return html.Div("Sem dados.", className="alert alert-warning")

        # aplica filtros
        d = df.copy()
        for col, sel in active_filters.items():
            if col in d.columns:
                d = d[d[col].astype(str).isin(sel)]

        # escolhe colunas seguras (sem PII)
        cols_show = [c for c in d.columns if c not in {"orig_answer","survey_id"} and not is_pii(c)]
        if "respondent_id" in cols_show:
            cols_show = ["respondent_id"] + [c for c in cols_show if c != "respondent_id"]

        sample = d[cols_show].copy() if cols_show else d.head(0)
        return dbc.Table.from_dataframe(sample.head(300), striped=True, bordered=True, hover=True, size="sm", responsive=True)
    
    except Exception as e:
        app.server.logger.exception("Erro no callback update_raw_table")
        return _error_box("Erro no callback update_raw_table", e)



# ==============================
# 13) Drill da Pivot (modal)
# ==============================
@dash.callback(
    Output("pv-drill-modal", "is_open"),
    Output("pv-drill-title", "children"),
    Output("pv-drill-content", "children"),
    Input("pv-out-chart-graph", "clickData"),
    State("pv-rows", "value"),
    State("pv-cols", "value"),
    State("pv-qid", "value"),
    State("pv-use-answer", "value"),
    State("pv-answer-binning", "value"),
    State("pv-daterange", "start_date"),
    State("pv-daterange", "end_date"),
    Input("current-key","data"),
    Input("current-env","data"),
    prevent_initial_call=True
)
def pivot_drill(clickData, rows, cols, pv_qid, pv_use_answer, pv_bins, ds, de, key, env_resolved):
    try:
        key = key or os.getenv("KEY","")
        env_resolved = normalize_env(env_resolved or "dev")

        df = load_df_for_key(env_resolved, key) if key else pd.DataFrame()
        if not clickData or df.empty:
            return False, "", ""
        d = df.copy()

        if ds and de and "date_of_response" in d.columns:
            d = d[(d["date_of_response"] >= ds) & (d["date_of_response"] <= de)]
        if pv_qid:
            d = d[d["question_id"].astype(str) == str(pv_qid)].copy()
            qtype = analyze_qtype(d["answer"]) if not d.empty else None
            wants_answer_dim = pv_use_answer and ("on" in (pv_use_answer or []))
            if wants_answer_dim and qtype != "text":
                try:
                    bins = int(pv_bins) if str(pv_bins) in {"5","10","20"} else 10
                except Exception:
                    bins = 10
                d = make_pv_answer(d, bins=bins)

        rows = rows if isinstance(rows, list) else ([rows] if rows else [])
        cols = cols if isinstance(cols, list) else ([cols] if cols else [])

        pt = clickData["points"][0]
        custom = pt.get("customdata") or []
        xval = custom[0] if len(custom) >= 1 else pt.get("x")
        cval = custom[1] if len(custom) >= 2 else None

        if rows:
            dimx = rows[-1]
            if dimx in d.columns:
                d = d[d[dimx].astype(str) == str(xval)]
        if cols:
            dimc = cols[0]
            if dimc in d.columns and cval is not None:
                d = d[d[dimc].astype(str) == str(cval)]

        state = build_state(df)
        qdesc_map = state.get("QDESC_MAP", {})
        title = qdesc_map.get(str(pv_qid), "Respostas") if pv_qid else "Respostas"
        if d.empty:
            return True, f"Respostas ‚Äì {title}", html.Div("Nenhum registro para este ponto.", className="text-muted")

        show_cols = ["date_of_response","category","topic","sentiment","answer"]
        show_cols = [c for c in show_cols if c in d.columns]
        tbl = d[show_cols].copy().sort_values("date_of_response", na_position="last")
        if "date_of_response" in tbl.columns:
            tbl["date_of_response"] = pd.to_datetime(tbl["date_of_response"], errors="coerce").dt.strftime("%d/%m/%Y %H:%M")

        table = dbc.Table.from_dataframe(tbl.head(1000), striped=True, bordered=False, hover=True, size="sm", responsive=True)
        return True, f"Respostas ‚Äì {title}", table
    
    except Exception as e:
        app.server.logger.exception("Erro no callback pivot_drill")
        return True, "Erro", _error_box("Erro no callback pivot_drill", e)

# ==============================
# 14) Run
# ==============================
if __name__ == "__main__":
    print(f"[RUN] Starting Dash on 0.0.0.0:{PORT} | BASE_PATH={BASE_PATH}")
    app.run(debug=False, host="0.0.0.0", port=PORT)
